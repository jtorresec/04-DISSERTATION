\textual
\pagestyle{simple}
\parindent 1.50cm

\chapter{Apresentação e análise dos resultados}

```{r sources.temp, message=FALSE, include=FALSE, eval=FALSE, results='hide', warning=FALSE}
#purl("~/Desktop/04-DISSERTATION/04-method.Rmd", documentation = 1,
#     output = "~/Desktop/04-DISSERTATION/01-data/method.R")
#purl("~/Desktop/04-DISSERTATION/02-bankingstructure.Rmd", documentation = 1,
#     output = "~/Desktop/04-DISSERTATION/01-data/banking.R")
#purl("~/Desktop/04-DISSERTATION/TEMP/03-spread.Rmd", documentation = 1,
#    output = "~/Desktop/04-DISSERTATION/01-data/spread.R")

source("~/Desktop/04-DISSERTATION/01-data/method.R")
source("~/Desktop/04-DISSERTATION/01-data/banking.R")
source("~/Desktop/04-DISSERTATION/01-data/spread.R")
```

```{r sources.banks, message=FALSE, warning=FALSE, results='hide'}
data.bank.location <- "~/Desktop/04-DISSERTATION/17-functions/databank.R"

data.zip <- "~/Desktop/04-DISSERTATION/01-data/bacen/bankdata/ZIP/"
data.csv <- "~/Desktop/04-DISSERTATION/01-data/bacen/bankdata/CSV/"
balance.location <- "~/Desktop/04-DISSERTATION/01-data/bacen/bankdata/"

source(data.bank.location)
```

```{r data.model, eval=FALSE, include=TRUE, message=FALSE, results='hide'}
banks.data <- readRDS(paste(balance.location, "banks.data.rds", sep = ""),
                      refhook = NULL)

banks.data.tax <- banks.data[118:239]

banksDfTaxJoin <- ldply(banks.data.tax, data.frame)

DfTaxNames <- c('DATA_BASE', "DOCUMENTO", "CNPJ", "AGENCIA",
                "NOME_INSTITUICAO", "COD_CONGL", "NOME_CONGL", 
                "TAXONOMIA", "CONTA", "NOME_CONTA", "SALDO", "DATA")

colnames(banksDfTaxJoin) <- DfTaxNames

banksDfTax <- 
        banksDfTaxJoin[c(-12:-14)] %>%
        filter(DOCUMENTO != "", DOCUMENTO != "DOCUMENTO")  %>% slice(2:n()) %>%
        mutate(DATA = as.yearmon(paste(str_sub(DATA_BASE, start = 1, end = -3),
                            str_sub(DATA_BASE, start = 5), sep = "-"))) %>% 
        type_convert(col_types = cols(DOCUMENTO = col_factor(),
                                      CNPJ = col_factor(),
                                      TAXONOMIA = col_character(),
                                      NOME_INSTITUICAO = col_factor(),
                                      DATA = col_number(),
                                      CONTA = col_factor()),
                     trim_ws = TRUE,
                     locale = locale(decimal_mark = ",")) %>%
        select(-AGENCIA, -COD_CONGL, -NOME_CONGL) %>%
        filter(DOCUMENTO == 4010) %>% 
        na.omit()

banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCO DO BRASIL - BANCO MULTIPLO"] <- "BANCO DO BRASIL"

banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCO NACIONAL DE DESENVOLVIMENTO ECONOMICO SOCIAL"] <- "BNDES"

banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCOS DE CÂMBIO"] <-
  "BANCOS DE CAMBIO"

#######
#banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCO DO BRASIL - BANCO MULTIPLO"] <- "BANCOS MULTIPLOS"

#banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCO NACIONAL DE DESENVOLVIMENTO ECONOMICO SOCIAL"] <- "BANCOS DE DESENVOLVIMENTO"

#banksDfTax$TAXONOMIA[banksDfTax$TAXONOMIA == "BANCOS DE CÂMBIO"] <- "BANCOS DE CAMBIO"
######

banksDfTaxSub <- 
        banksDfTax #%>%  
        #subset(year(DATA) == c(2012:2020)) #| DATA_BASE == 201202 | DATA_BASE == 201203 | DATA_BASE == 201204 | DATA_BASE == 201205 | DATA_BASE == 201206
         #     ) %>%
        #select(DATA, NOME_INSTITUICAO, TAXONOMIA, CONTA, SALDO)
        #subset(NOME_INSTITUICAO == "BCO DO BRASIL S.A." | NOME_INSTITUICAO == "CAIXA ECONOMICA FEDERAL" #| NOME_INSTITUICAO == "BANCO INTERMEDIUM S/A"
          #     )

banksDfSpfill <- banksDfTax %>% expand(DATA, CNPJ, CONTA)

banksDfSp <- banksDfSpfill %>% 
        left_join(banksDfTaxSub) %>%
        select(DATA, CNPJ, NOME_INSTITUICAO, TAXONOMIA, CONTA, SALDO) %>% 
        spread(CONTA, SALDO, fill = 0) %>%
        filter(`16000001` != 0 & `71100001` != 0 & `81100008` !=0 
               & `41000007` != 0 & year(DATA) != 2010 
               #& year(DATA) != 2011
               )
saveRDS(banksDfSp, file = "~/Desktop/04-DISSERTATION/01-data/model/banksDfSp.RDS")

saveRDS(banksDfTax, file = "~/Desktop/04-DISSERTATION/01-data/model/banksDfTax.RDS")

```

```{r read.DfSp}

banksDfTax <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/banksDfTax.RDS")

banksDfSp <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/banksDfSp.RDS")

back.acc <- banksDfSp %>% select(DATA, CNPJ, NOME_INSTITUICAO, `41000007`, `16000001` ) %>% mutate(DATA = DATA + (1/12)) %>% mutate(`41000007 -1` = `41000007`, `16000001 -1` = `16000001` ) %>% select(DATA, CNPJ, `41000007 -1`, `16000001 -1`)
```

```{r data.model.agregates, eval=TRUE, message=FALSE, warning=FALSE, include=TRUE}
#IPCA
ipca_cod <- as.character(data.table[5,3])
ipca <- ipeadata(code = ipca_cod, language = c('br'))

ipcaDt <- ipca %>% 
        mutate(DATA = as.yearmon(date) + 0.2, 
                  IPCA = value / 100) %>% select(DATA, IPCA) 

selic.copom <- ipeadata(code = 'BM366_TJOVER366', language = "br") 
selicMeta <- selic.copom %>% 
        mutate(DATA = as.yearmon(date) + 0, 
               SelMet = value / 100) %>%
        group_by(DATA) %>% 
        summarise(SelMet = mean(SelMet)) %>% 
        select(DATA, SelMet)

selic_cod <- as.character(data.table[3,3])
selic <- ipeadata(code = selic_cod, language = "br")
selicDt <- selic %>% 
        mutate(DATA = as.yearmon(date) + 0.2, SelOvr = value / 100) %>% 
        select(DATA, SelOvr)

Mpa4Dt <- m2m3m4.data %>% 
        mutate(DATA = as.yearmon(Data) + 0.2) %>%
        mutate(MPA4 = (M4 * 1000) / 1) %>% 
        select(DATA, MPA4)

Mpa2Dt <- m2m3m4.data %>% 
        mutate(DATA = as.yearmon(Data) + 0.2) %>%
        mutate(MPA2 = (M2 * 1000) / 1) %>% 
        select(DATA, MPA2)

TitPub <- money.base.comps %>% 
  select(Data, Titulos.Públicos.Totais) %>% 
  filter(Titulos.Públicos.Totais != "-") %>% 
  mutate(DATA = as.yearmon(Data),
         TitPub = as.numeric(as.character(Titulos.Públicos.Totais))) %>% 
  select(DATA, TitPub)

PIB_cod <- as.character(data.table[2,3])
PIB <- ipeadata(code = PIB_cod, language = "br")

PIBDt <- PIB %>% 
        mutate(DATA = as.yearmon(date) + 0.2, 
               PIB = (value * 1000000) / 1) %>% 
        select(DATA, PIB)

BMa_cod <- as.character(data.table[9,3]) 
Bma <- money.base %>% 
        transform(DATA = as.yearmon(Data) + 0.2) %>%
        filter(Base.Monetária.Ampliada != "-") %>%
        slice(7:n()) %>% 
        transform(BMA = (as.numeric(as.character(Base.Monetária.Ampliada)) *
                          1000) / 1) %>% 
        select(DATA, BMA)

Bmr <- money.base %>%  
        transform(DATA = as.yearmon(Data) + 0.2) %>%
        slice(7:n()) %>% 
        transform(BMR = (as.numeric(as.character(Base.Monetária)) *
                          1000) / 1) %>% 
        select(DATA, BMR)

dc.local <- "~/Desktop/04-DISSERTATION/01-data/bacen/compulsory/STP-20210312091217949.xlsx"

DepCom  <-  
        read_xlsx(dc.local, sheet = "STP-20210312091217949", 
                  col_types = c("date", "numeric", "numeric", 
                                "numeric", "numeric"),
                  trim_ws = TRUE)

DepComDt <- DepCom %>% transform(DATA = as.yearmon(DATA),
                                 (COMP_TOTAL = COMPULSORIO_TOTAL * 1000) /
                                         1) %>% 
        select(DATA, COMPULSORIO_TOTAL) 

SprEa <- spread.moct %>% separate(data, sep = "/", 
                                  into = c("DIA", "MES", "ANO")) %>%
        mutate(DATA = as.yearmon(paste(ANO, MES, sep = "-")) + 0) %>%
        mutate(SprEa = Spread.MOCT / 100) %>% 
        select(DATA, SprEa)
```

```{r market.total}

OpCrT <- banksDfSp %>% group_by(DATA) %>% 
        summarize(OpCrTotal = sum(`16000001`) +  sum(`18000009`))

NInst <- banksDfTax %>% group_by(DATA) %>% 
        summarise(NUM_INSTITUICOES = length(unique(NOME_INSTITUICAO)))

RcTotal <- banksDfSp %>% group_by(DATA) %>% 
        summarise(RECEITA_TOTAL = sum(`71000008`))

GCSum <- banksDfSp %>% 
        inner_join(NInst, by = "DATA") %>%
        inner_join(OpCrT, by = "DATA") %>% 
        group_by(DATA) %>%
        summarise(GCSum = sum(((`16000001` / OpCrTotal) -
                                         (1 / NUM_INSTITUICOES)) ^ 2)
        )

GC <- GCSum %>% 
        inner_join(NInst, by = "DATA") %>%
        group_by(DATA) %>%
        summarise(GrCon = (1 / NUM_INSTITUICOES) + 
                          (NUM_INSTITUICOES * (GCSum / NUM_INSTITUICOES)) )

# PERCENTUAL DE PROVISÃO OBRIGATÓRIO DE ACORDO COM O RISCO DE CRÉDITO
ra <- 0.005 ; rb <- 0.01 ; rc <- 0.03; rd <- 0.10; re <- 0.30; rf <- 0.5; rg <- 0.7; rh <- 1

```

```{r pure.panel, message=FALSE}

pure.panel.uni <- banksDfSp %>%
        left_join(back.acc) %>% 
        inner_join(OpCrT, by = "DATA") %>%
        inner_join(NInst, by = "DATA") %>%
        inner_join(RcTotal, by = "DATA") %>%
        inner_join(GC, by = "DATA") %>%
        inner_join(selicDt, by = "DATA") %>%
        left_join(selicMeta, by = "DATA") %>%
        inner_join(ipcaDt, by = "DATA") %>%
        inner_join(Mpa2Dt, by = "DATA") %>%
        inner_join(Mpa4Dt, by = "DATA") %>%
        inner_join(DepComDt, by = "DATA") %>%
        inner_join(PIBDt, by = "DATA") %>%
        inner_join(SprEa, by = "DATA") %>%
        inner_join(Bmr, by = "DATA") %>%
        inner_join(Bma, by = "DATA") %>%
        left_join(TitPub, by = "DATA") %>%
        mutate(OSprEp = ( (`71100001`)  / 
                             ( (1/2)*(`16000001` + `16000001 -1`))) -
                       ((`81100008`*-1) / ((1/2)*(`41000007`+`41000007 -1`)) )
                                               ) %>%
        mutate(SprEp = (`71000008` / ( (1/2)*(`16000001` + `18000009`))) -
                       ((`81100008`*-1) / ((1/2)*(`41000007`+`41000007`)) )
                                               ) %>%
        mutate(TxApl = (`71000008` / ( (1)*(`16000001` + `18000009`))) ) %>%
        mutate(TxCap = ( (`81100008`*-1) / ((1/2)*(`41000007`+`41000007`)) )) %>%
        mutate(TpIns = as.factor(TAXONOMIA)) %>% 
        mutate(BANCO = as.factor(NOME_INSTITUICAO)) %>%
        mutate(lnOpCrMkt =  (OpCrTotal / 1)   ) %>%
        mutate(lnMPA2 = ((MPA2)/1)) %>%
        mutate(lnMPA4 = ((MPA4)/1)) %>%
        mutate(BMR = ((BMR)/1)) %>%
        mutate(BMA = ((BMA)/1)) %>%
        mutate(OpCr = (((`16000001` + (`16900008` * -1))) / 1) ) %>%
        mutate(OtCr = (((`18000009` + (`18900006` * -1)))/ 1)) %>%
        mutate(OpTot = (  (  (`16000001` + (`16900008` * -1)  ) + 
                     (`18000009` + (`18900006` * -1) )  ) /1  )  ) %>%  
        mutate(lnOpTot = log(  (  (`16000001` + (`16900008` * -1)  ) + 
                     (`18000009` + (`18900006` * -1) )  ) /1  )  ) %>%
        mutate(OpEmp = (`16100004` / (1))) %>% 
        mutate(OpFin = ((`16200007`+ `16300000` + `16400003`) / (1)) ) %>% 
        mutate(OtOp = ((`16800005` + `18000009`) / (1)) ) %>% 
        mutate(Inad = ( ( (`16900008` + `18900006`) * -1) / (1)) )%>%
        mutate(Rent = (`89000007` / `71000008`) * 1) %>%
        mutate(Disp = ((`11000006`) / 1)) %>% 
        mutate(lnAtv = (`39999993` / 1)  ) %>% 
        mutate(RcPd = (((`31100003` * ra) +
                              (`31200006` * ra) + (`31300009` * rb) +
                              (`31400002` * rc) + (`31500005` * rd) +
                              (`31600008` * re) + (`31700001` * rf) +
                              (`31800004` * rg) + (`31900007` * rh) /
                              (ra + ra + rb + rc + rd + re + rf + rg + rh)) /
                              (`16000001`) ) * 1  ) %>%
        mutate(RcCr = (`31000000`/1) ) %>%
        mutate(MkSh = ( ((`16000001` + `18000009`)  / OpCrTotal) * 1) ) %>%
        mutate(Comp = ((COMPULSORIO_TOTAL) / 1)  )  %>%
        mutate(VelMo =  (  (  (PIB * 1) * (1 - IPCA) ) / 
                                   (BMA * 1)  )   
               ) %>%

        mutate(Cx = (`11100009`) / 1) %>%
        mutate(lnROp = (`71000008` / 1)  ) %>% # receitas operacionais
        mutate(ROp = ((`71000008`/1)) ) %>% # receitas operacionais
        mutate(ROpCr = ((`71100001` / 1) / 1)  ) %>% # receitas operações de crédito 
        mutate(RSrv = ((`71700009` / 1) / 1)  ) %>% # receitas serviços 
        mutate(RPart = ((`71800002` / 1) / 1)  ) %>% # receitas participações 
        mutate(OtROp = ((  (`71000008` - 
                       (`71100001` + `71700009` + `71700009` 
                        + `71800002`) 
                                ) / 1 )  / 1) ) %>% 
        mutate(Inv = ((`21000003`) / 1 )  ) %>%
        mutate(ImpInd = ((`49100002` / 1))  ) %>% 
        mutate(ImpRend = ( (`89400009` * -1) / 1 ) ) %>%
        mutate(DepTot = (`41000007` / 1 )) %>% 
        mutate(DepAv = (`41100000` / (1)) ) %>% 
        mutate(DepPop = (`41200003` / (1) )  ) %>% 
        mutate(DepIf = (`41300006` / (1)) ) %>% 
        mutate(DepAp = (`41500002` / (1)) ) %>% 
        mutate(OtDep = (`41000007`- `41100000` - `41200003` - `41300006` -
                       `41500002`) / (1)) %>%
        mutate(EPr = (((`16000001` + `18000009` ) - DepTot) / (1))
               ) %>%
        mutate(DesOp = ((`81000005` * -1) / 1 )) %>% 
        mutate(DesCap = ((`81100008` * -1) / 1) ) %>% 
        mutate(DAdm = ((`81700006` * -1) / ( 1 ) ) ) %>%
        mutate(OtDes = (  (  (`81000005` * -1) - 
                       (`81100008` * -1) - (`81700006`* -1 ) ) 
                       / ( 1 ) ) 
               ) %>%
        mutate(PrtLc = ((`89700008` * -1) / 1)  ) %>%
        mutate(PtLq = (`61000001` / 1) ) %>% 
        mutate(Int = (`25000009` / 1 ) ) %>% 
        subset(TpIns != "BANCOS COMERCIAIS COOPERATIVOS"  
               & TpIns != "BANCOS MULTIPLOS COOPERATIVOS"
               & TpIns != "BANCOS COMERCIAIS ESTRAGEIROS - FILIAL PAIS"
               & year(DATA) != 2021
               #& SprEp > -0.10 & SprEp < 0.56
               )  %>% 
        na.omit() %>%
        as_tibble()
```

```{r banks.model, message=FALSE}

banksPanel <- banksDfSp %>%
        left_join(back.acc) %>% 
        inner_join(OpCrT, by = "DATA") %>%
        inner_join(NInst, by = "DATA") %>%
        inner_join(RcTotal, by = "DATA") %>%
        inner_join(GC, by = "DATA") %>%
        inner_join(selicDt, by = "DATA") %>%
        left_join(selicMeta, by = "DATA") %>%
        inner_join(ipcaDt, by = "DATA") %>%
        inner_join(Mpa2Dt, by = "DATA") %>%
        inner_join(Mpa4Dt, by = "DATA") %>%
        inner_join(DepComDt, by = "DATA") %>%
        inner_join(PIBDt, by = "DATA") %>%
        inner_join(SprEa, by = "DATA") %>%
        inner_join(Bmr, by = "DATA") %>%
        inner_join(Bma, by = "DATA") %>%
        left_join(TitPub, by = "DATA") %>%
        mutate(OSprEp = ( (`71100001`)  / 
                             ( (1/2)*(`16000001` + `16000001 -1`))) -
                       ((`81100008`*-1) / ((1/2)*(`41000007`+`41000007 -1`)) )
                                               ) %>%
        mutate(SprEp = (`71000008` / ( (1/2)*(`16000001` + `18000009`))) -
                       ((`81100008`*-1) / ((1/2)*(`41000007`+`41000007`)) )
                                               ) %>%
        mutate(TxApl = (`71000008` / ( (1/2)*(`16000001` + `18000009`))) ) %>%
        mutate(TxCap = ( (`81100008`*-1) / 
                           (( 1/2 )*(`41000007`+`41000007`)) )) %>%
        mutate(TpIns = as.factor(TAXONOMIA)) %>% 
        mutate(BANCO = as.factor(NOME_INSTITUICAO)) %>%
        mutate(lnOpCrMkt =  log(OpCrTotal / 1)   ) %>%
        mutate(lnMPA2 = log((MPA2)/1)) %>%
        mutate(lnMPA4 = log((MPA4)/1)) %>%
        mutate(lnBMR = log(BMR)/1) %>%
        mutate(lnBMA = log(BMA)/1) %>%
        mutate(OpCr = ((`16000001` + (`16900008` * -1))) / 1) %>%
        mutate(OtCr = ((`18000009` + (`18900006` * -1)))/ 1) %>%
        mutate(OpTot = (  (  (`16000001` + (`16900008` * -1)  ) + 
                     (`18000009` + (`18900006` * -1) )  ) /1  )  ) %>%
        mutate(lnOpTot = log(  (  (`16000001` + (`16900008` * -1)  ) + 
                     (`18000009` + (`18900006` * -1) )  ) /1  )  ) %>%
        mutate(OpEmp = `16100004` / (OpCr + OtCr)) %>% 
        mutate(OpFin = (`16200007`+ `16300000` + `16400003`) 
               / (OpCr + OtCr) ) %>% 
        mutate(OtOp = (`16800005` + `18000009`) / (OpCr + OtCr) ) %>% 
        mutate(Inad = ( ( (`16900008` + `18900006`) * -1) / (OpCr + OtCr))) %>%
        mutate(Rent = (`89000007` / `71000008`) * 1) %>%
        mutate(Disp = (`11000006`) / OpTot) %>% 
        mutate(lnAtv = log(`39999993` / 1)  ) %>% 
        mutate(RcPd = (  (  (`31100003` * ra) +
                              (`31200006` * ra) + (`31300009` * rb) +
                              (`31400002` * rc) + (`31500005` * rd) +
                              (`31600008` * re) + (`31700001` * rf) +
                              (`31800004` * rg) + (`31900007` * rh) /
                              (ra + ra + rb + rc + rd + re + rf + rg + rh) ) /
                              ( OpTot ) ) * 1  ) %>%
        mutate(RcCr = (`31000000`/ OpTot)) %>%
        mutate(lnRcCr = (RcCr) ) %>%
        mutate(MkSh = ( ((`16000001` + `18000009`)  / OpCrTotal) * 1) ) %>%
        mutate(lnComp = log(COMPULSORIO_TOTAL) / 1) %>%
        mutate(Comp = ((COMPULSORIO_TOTAL) / OpCrTotal)  )  %>%      
        mutate(VelMo =  (  (  (PIB * 1) * (1 - IPCA) ) / 
                                   (BMA * 1)  )   ) %>%

        mutate(Cx = (`11100009`) / OpTot) %>%
        mutate(lnROp = log(`71000008` / 1)  ) %>% # operacionais
        mutate(ROp = (`71000008`/1)) %>% # receitas operacionais
        mutate(ROpCr = ((`71100001` / 1) / ROp)) %>% #  crédito 
        mutate(RSrv = ((`71700009` / 1) / ROp)) %>% # serviços 
        mutate(RPart = ((`71800002` / 1) / ROp)) %>% #  participações 
        mutate(OtROp = (  (`71000008` - 
                       (`71100001` + `71700009` + `71700009` 
                        + `71800002`) 
                                ) / 1 )  / ROp ) %>% 
        mutate(Inv = (`21000003`) / `39999993` ) %>%
        mutate(ImpInd = (`49100002` / ROp)) %>% 
        mutate(ImpRend = ( (`89400009` * -1) / ROp) ) %>%
        mutate(DepTot = (`41000007`)) %>% 
        mutate(DepAv = (`41100000` / (DepTot))) %>% 
        mutate(DepPop = (`41200003` / (DepTot))) %>% 
        mutate(DepIf = (`41300006` / (DepTot))) %>% 
        mutate(DepAp = (`41500002` / (DepTot))) %>% 
        mutate(OtDep = (`41000007`- `41100000` - `41200003` - `41300006` -
                       `41500002`) / (DepTot)) %>%
        mutate(EPr = (((`16000001` + `18000009` ) - DepTot) / (OpCr + OtCr))
               ) %>%
        mutate(DesOp = (`81000005` * -1) / 1) %>% 
        mutate(DesCap = (`81100008` * -1) / DepTot) %>% 
        mutate(DAdm = ((`81700006` * -1) / ( OpTot ) )) %>%
        mutate(OtDes = (  (  (`81000005` * -1) - 
                       (`81100008` * -1) - (`81700006`* -1 )) 
                       / ( OpTot ) ) 
               ) %>%
        mutate(PrtLc = ((`89700008` * -1) / 1)  ) %>%
        mutate(PtLq = `61000001` / 1) %>% 
        mutate(Int = (`25000009` / `39999993`)) %>% 
        subset(TpIns != "BANCOS COMERCIAIS COOPERATIVOS"  
               & TpIns != "BANCOS MULTIPLOS COOPERATIVOS"
               & TpIns != "BANCOS COMERCIAIS ESTRAGEIROS - FILIAL PAIS"
               & year(DATA) != 2021
               #& SprEp > -0.10 & SprEp < 0.56
               )  %>% 
        na.omit() %>%
        #select(DATA, NUM_INSTITUICOES, BANCO, SprEp, Rent, LcLq,
        #       TpIns, EPr, EAv, EAp, DAdm, Inad, Vol, Tam, Rc, MkSh, 
        #       GrCon, Comp, PIB, IPCA, SelMet, MPA4, MPA2, VelMo, SprEa, BMR, BMA, SelOvr, Cx, RcSrv) %>% 
          
        #subset(SprEp < .5 & 
        #               SprEp != "Inf" 
        #       & DAdm <= 0.75 & EPr < 0.87 & Inad < 0.1 & EAv < 0.1 
        #       &  EAp <= 0.9 & Rc < 1
        as_tibble()
```

Em análise preliminar no conjunto de dados, levando em consideração as variáveis calculadas, percebeu-se que a fórmula para *spread ex-post* (\autoref{eq:sprbase}) apresentada por \textcite{dantas:2012} e \textcite{timotio:2018} não é adequada para avaliar o mercado bancário como todo, diante o fato de haver diferenças operacionais e operações de múltiplas carteiras. 

A \autoref{table.spread.a} mostra o resultado do cálculo do *spread ex-post* conforme \autoref{eq:sprbase}, levando em consideração as receitas de crédito, operações de crédito, custo de captação e depósitos totais, com resultados que não refletem todas as operações exercidas pelas instituições.

\begin{table}
\caption{Cálculo \emph{Spread ex-post} com base nas Receitas de operações de crédito}
\vspace{1mm}
```{r table.spread.a}
table.spread.a <- banksPanel %>% #filter(CNPJ == "60701190") %>% 
        group_by(year(DATA)) %>% 
        summarise(Capital.Emprestado = sum(`16000001`) / 1000000,
                  Receitas.Operações.Crédito = sum(`71100001`) / 1000000,
                  Tx.Aplicação =  (Receitas.Operações.Crédito /
                          Capital.Emprestado) * 100,
                  Despesas.Captação = sum(`81100008` * -1) / 1000000,
                  Depósitos.Totais = sum(`41000007`) / 1000000,
                  Tx.Captação = (Despesas.Captação / Depósitos.Totais) * 100,
                  SPREAD = Tx.Aplicação - Tx.Captação) %>%
        mutate(DATA = `year(DATA)`) %>% 
        select(DATA, SPREAD, Tx.Aplicação,  Tx.Captação)

table.spread.a %>% kbl(booktabs = T) %>% 
        kable_styling(latex_options = "striped",
                      font_size = 10, full_width = T)
```
\vspace{1mm}
\label{table.spread.a}
\fonte{Densenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

Diante esta observação, foi realizado um cálculo para o *spread ex-post* (\autoref{eq:newspr}), de tal modo que captasse as diferenças entre modalidades bancárias e operações das instituições, levando em consideração todas as receitas operacionais e as operações de crédito e outros créditos chegando ao resultado médio demonstrado na \autoref{table.spread.b}, sendo mais aproximado com as séries do *Spread* MOC e *Spread* do ICC.

\begin{table}
\caption{Spread Ex-post com base na operações totais}
\vspace{1mm}
```{r table.spread.b}
table.spread.b <- banksPanel %>% #filter(CNPJ == "60701190") %>%
        group_by(year(DATA)) %>%
        #group_by(TpIns) %>%
        summarise(Capital.Emprestado = (sum(`16000001`) + sum(`16900008`)) /
                          1000000,
                  Receitas.Operações.Crédito = sum(`71000008`) / 1000000,
                  Tx.Aplicação =  (Receitas.Operações.Crédito /
                          Capital.Emprestado) * 100,
                  Despesas.Captação = sum(`81100008` * -1) / 1000000,
                  Depósitos.Totais = sum(`41000007`) / 1000000,
                  Tx.Captação = (Despesas.Captação / Depósitos.Totais) * 100,
                  SPREAD = Tx.Aplicação - Tx.Captação) %>%
        mutate(DATA = `year(DATA)`) %>% 
        select(DATA, SPREAD, Tx.Aplicação,  Tx.Captação)

table.spread.b %>% 
        kbl(booktabs = TRUE) %>% 
        kable_styling(latex_options = "striped",
                      font_size = 10, full_width = T)
```
\vspace{1mm}
\label{table.spread.b}
\fonte{Densenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

\begin{equation}\label{eq:newspr}
SprEp = \frac{RcOp}{\frac{1}{2} [OpTot_{t} + OpTot_{t-1}]} - \frac{DesCap}{\frac{1}{2} [ DepTot_{t} + DepTot_{t-1}] }
\vspace{2mm}
\end{equation}

Outro aspecto em relação as informações contábeis é que a conta de operações de crédito (16000001) já se apresenta reduzida do valor de provisão para operações de crédito (16900008) — uma *proxy* para a inadimplência para cada instituição —, podendo levar a equívocos na utilização destas duas variáveis sem o tratamento adequados. Para fins de estimação o valor da inadimplência foi inserido na operação de crédito e a inadimplência calculada como percentual deste valor.

Em análise descritiva foram encontradas anomalidades nas variáveis ($Inad$) e ($OtDes$) — participação sobre a operação de crédito total — de observações acima do terceiro quartil, comprometendo outras variáveis. Essas observações foram eliminadas utilizando a variação interquartil (IQR) até o máximo de 1.5 do terceiro quartil, o que veio normalizar estas variáveis e as demais.

A variação interquartil também foi utiliza para retirar observações referentes a variável dependente *Spread Ex-post*, que apresentavam destoantes da normalidade, podendo prejudicar os resulatdos da modelagem econométrica. 

```{r summary.data}

banksCols <- banksPanel %>% select(-DATA, -BANCO, -TAXONOMIA, -CNPJ, -NOME_INSTITUICAO, -TpIns) %>% colnames()

banksColsOr <- banksCols[1:204]

qDAdm <- quantile(banksPanel$DAdm, probs=c(.25, .75), na.rm = FALSE)
iqrDAdm <- IQR(banksPanel$DAdm)

upDAdm <- qDAdm[2] + (iqrDAdm * 1.5)
lowDAdm <- qDAdm[1] - (iqrDAdm * 1.5)

qInad <- quantile(banksPanel$Inad, probs=c(.25, .75), na.rm = FALSE)
iqrInad <- IQR(banksPanel$Inad)

upInad <- qInad[2] + (iqrInad * 1.5)
lowInad <- qInad[1] - (iqrInad * 1.5)

qOtDes <- quantile(banksPanel$OtDes, probs = c(.25, .75), na.rm = FALSE)
iqrOtDes <- IQR(banksPanel$OtDes)

upOtDes <- qOtDes[2] + (iqrOtDes * 1.5)
lowOtDes <- qOtDes[1] - (iqrOtDes * 1.5)

qRcPd <- quantile(banksPanel$RcPd, probs = c(.25, .75), na.rm = FALSE)
iqrRcPd <- IQR(banksPanel$RcPd)

upRcPd <- qRcPd[2] + (iqrRcPd * 1.5)
lowRcPd <- qRcPd[1] - (iqrRcPd * 1.5)

qSprEp <- quantile(banksPanel$SprEp, probs = c(.25, .75), na.rm = FALSE)
iqrSprEp <- IQR(banksPanel$SprEp)

upSprEp <- qSprEp[2] + (iqrSprEp * 1.5)
lowSprEp <- qSprEp[1] - (iqrSprEp * 1.5)


qDesCap <- quantile(banksPanel$DesCap, probs = c(.25, .75), na.rm = FALSE)
iqrDesCap <- IQR(banksPanel$DesCap)

upDesCap <- qDesCap[2] + (iqrDesCap * 1.5)
lowDesCap <- qDesCap[1] - (iqrDesCap * 1.5)



obs.banks <- banksPanel %>% 
  group_by(BANCO) %>% 
  summarise(OBS = sum(length(BANCO))) %>% select(BANCO, OBS)

banksPanel.00 <- banksPanel %>% 
  select(-all_of(banksColsOr)) %>% 
  left_join(obs.banks, by = "BANCO") %>% 
  subset(DAdm < upDAdm
         #& SprEp > lowSprEp & SprEp < upSprEp
         #&Inad <= upInad 
         #& RcPd <= upRcPd
         & DesCap > lowDesCap & DesCap < upDesCap
         & OtDes <= upOtDes)

#outliers <- boxplot(banksPanel.00$SprEp, plot=FALSE)$out

#banksPanel.00 <- banksPanel.00[-which(banksPanel.00$SprEp %in% outliers), ]
banksPanel.00$SprEp %>% summary()

```

\begin{table}
\caption{Resultado descritivo do \emph{Spread Ex-post} após retiradas de outliers}
\vspace{1mm}
```{r summary.spread, eval=TRUE, message=FALSE, results='hide'}
#summSpr <- banksPanel.01$SprEp %>% summary()

#names.stat <- c("Min.",  "1st Qu.", "Median", "Mean", "3rd Qu.", "Max.")
data.frame("Minimo" = -0.24948,
           "Prim Quartil" = 0.08001 ,
           "Mediana" = 0.16046,
           "Média" = 0.20167,
           "Ter Quartil" = 0.28533,
           "Máximo" = 0.70103) %>% kbl(booktabs = T) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)
  

```
\vspace{1mm}
\label{tb:summspr}
\fonte{Desenvolvido a partir dos resultados}
\vspace{-2mm}
\end{table}

Foi realizada avaliação de correlação entre as variáveis do painel de dados, e conforme \autoref{graf:corr} foi detectada forte correlação entre algumas variáveis, o que viria a causar diversos problemas de estimação. Para contornar essa questão foram excluídas variáveis autocorrelacionadas que apresentavam similaridades teóricas ou sem significância em estimações preliminares.

\begin{grafico}[!htbp]
\vspace{20pt}
\caption{Correlação entre variáveis do painel}
\vspace{-4mm}
```{r chart.correlation, fig.width=16}
banksPanel.00 %>% 
        select(EPr, DepAv, DepAp, DepPop, DepIf, OtDep,
               lnOpCrMkt, lnOpTot, lnMPA2, VelMo, SelMet, MkSh,
               lnAtv, DAdm, DesCap, OtDes, DesOp, ROp, ROpCr, Inad, IPCA, 
               RcPd, SprEa, OpEmp, OpFin, OtOp, GrCon, lnAtv) %>% 
        cor() %>% corrplot(method = "square", type = "full",
                           #addCoef.col = FALSE,
                           #hclust.method = "centroid"
                           tl.pos = "lt",
                           tl.cex = .8, tl.col = "black"
                           )
```
\vspace{-3mm}
\label{graf:corr}
\fonte{Desenvolvido a partir de dados coletados}
\vspace{-2mm}
\end{grafico}

Como método de apoio para avaliar a multicolineriedade foi utilzada a técnica de inflação da variância (VIF), identificando que algumas variáveis estavam inflando o modelo. Nesse sentido foram eliminadas variáveis que apresentaram valor VIF maior que 5. 

```{r lm.model, results='hide'}
library(car)
fit <- lm(SprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp #+ OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
          data = banksPanel.00)

fit %>% summary()
#vif(fit) > 5
```

Em ajuste preliminar foi verificado através da distância de Cook as observações que podem influenciar o modelo. O \autoref{graf:influence} demostra as observações, com tamando dos círculos proporcionais a distância de Cook. As observações que apresentaram uma elavada distância de Cook, acima do ponto de *cutoff*  ($4/N$) foram eliminadas do painel.    

\begin{grafico}[!htbp]
\vspace{20pt}
\caption{Visualização de influência resíduos}
\vspace{-4mm}
```{r influence.plot, fig.width=6, fig.height=4}
#layout(matrix(1:2, ncol = 2))
library(car)
a1 <- influencePlot(fit, 
              #id=list(method="identify"), 
              #main="Influence Plot", 
              sub =
                "O tamanho dos círculos é proporcional a distância de Cook's" 
              )
```
\vspace{-3mm}
\label{graf:influence}
\fonte{Desenvolvido a partir de dados coletados}
\vspace{-2mm}
\end{grafico}

```{r remove.outliers, results='hide' }
cooksd <- cooks.distance(fit)

sample_size <- nrow(banksPanel.00)
#plot(cooksd, pch="*", cex=2, main="Influential Obs by Cooks distance") %>%  # plot cook's distance
#abline(h = 4/sample_size, col="red")  %>% # add cutoff line
#text(x=1:length(cooksd)+1, y=cooksd, labels=ifelse(cooksd>4/sample_size, names(cooksd),""), col="red")  # add labels
```

O \autoref{graf:resstud} mostra a visualização entre os valores preditos em modelagem incial versus o redíduos studentizados deletados do modelo. No \autoref{graf:histsp} é demonstrado de forma comparativa o histograma dos resíduos antes e após tratamento de dados e retirada dos outliers. 

\begin{grafico}
\vspace{20pt}
\caption{Resíduos studentizados vs Valores Preditos}
\vspace{-4mm}
```{r fit.01, fig.width=6, fig.height=4}

# Removing Outliers
# influential row numbers
influential <- as.numeric(names(cooksd)[(cooksd > (4/sample_size))])

# Alternatively, you can try to remove the top x outliers to have a look
# top_x_outlier <- 2
# influential <- as.numeric(names(sort(cooksd, decreasing = TRUE)[1:top_x_outlier]))

banksPanel.01 <- banksPanel.00[-influential, ]

fit.01 <- lm(SprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp #+ OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
          data = banksPanel.01)
banksPanel.01 %>% summary()

library(olsrr)
ols_plot_resid_stud_fit(fit.01, print_plot = "TRUE")
```
\vspace{-3mm}
\label{graf:resstud}
\fonte{Desenvolvido a partir da modelagem de dados}
\vspace{-2mm}
\end{grafico}

No \autoref{graf:histsp} é possível visualizar a distribuição de frequência da variável *Spread Ex-post* antes e após a retitada dos *outliers*.

\begin{grafico}[!hbtp]
\vspace{20pt}
\caption{Histograma demonstrando o ajuste na variavel dependente}
\vspace{-4mm}
```{r hist.SprEp, fig.show="hold", out.width="100%", fig.width=6, fig.height=6}
library(grid)
library(ggplotify)
library(gridExtra)

par(mfrow=c(2,2)) 

par(mar = c(4, 4, .1, .1))

hist(banksPanel.00$SprEp, main = "Original",
     xlab = "Spread Ex-post")

hist(banksPanel.01$SprEp, main = "Tratamento",
     xlab = "Spread Ex-post")

```
\vspace{3mm}
\label{graf:histsp}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{grafico}

No \autoref{graf:histerr} é posssivel visualizar o comportamento de frequência dos resíduos antes e após a transformação dos dados.

\begin{grafico}[!hbtp]
\vspace{20pt}
\caption{Histograma dos Resíduos}
\vspace{-4mm}
```{r hist.residuals, fig.show="hold", out.width="100%", fig.width=6, fig.height=6}
library(grid)
library(ggplotify)
library(gridExtra)

par(mfrow=c(2,2)) 

par(mar = c(4, 4, .1, .1))

hist(fit$residuals, main = "Original",
     xlab = "Spread Ex-post")

hist(fit.01$residuals, main = "Tratamento",
     xlab = "Spread Ex-post")

```
\vspace{3mm}
\label{graf:histerr}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{grafico}


No \autoref{graf:disperr} é possível visualizar o diagrama de dispersão entre os resíduos estudentizados e os valores preditos


```{r data.disp.graf, results='hide'}
# Análise de Resíduos
predito <- fit.01$fit
residuo <- fit.01$res
cbind(predito,residuo)
# transformacoes dos residuos
z <- rstandard(fit.01)    # residuos padronizados
zstudent <- rstudent(fit.01)    # residuos studentizados
cbind(z,zstudent)
```

\begin{grafico}[!hbtp]
\caption{Diagrama de Dispensão dos resíduos}
\vspace{-4mm}
```{r erros.disp}
plot(predito, zstudent, pch=20, main=NULL, xlab="Predito", ylab="ResÍduo studentizado") %>%  abline(h=0) %>%  abline(h=2, lty=3) %>% abline(h=-2, lty=3)
```
\vspace{3mm}
\label{graf:disperr}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{grafico}

```{r residuals.analysis, eval=FALSE, message=FALSE, results='hide'}
# graficos de residuos
par(mfrow=c(2,2))
# residuo vs predito
plot(predito, residuo, pch=20, main="Diagrama de Dispersão", xlab="Predito", ylab="Residuo") %>% abline(h=0)
#q-q plot normal envelope
require(car) #para instalar o pacote use: install.packages()

qqPlot(residuo, pch=20, main="Q-Q Plot Normal", xlab="Quantis N(0,1)", ylab="Quantis Amostrais") # residuo transformado vs predito

#identificar n pontos clicando próximo aos pontos
identify(predito,zstudent,n=2)
```

```{r violin, message=FALSE, include=FALSE, eval=FALSE}
banksPanel.01 %>% group_by(DATA, BANCO) %>% 
  summarise(Soma = sum(n())) %>% 
  ggplot(aes(y = Soma, x = BANCO, fill = BANCO))+ 
        geom_violin(colour = "black",size= 2) + 
        xlab("Type") + ylab("Insect count")
```

```{r studdent.residuals, eval=FALSE, results='hide'}
plot(fit.01, which = 2)
car::qqPlot(residuals(fit.01))

car::residualPlots(fit.01, terms = ~ 1, fitted = T, 
              #id.n = 5, 
              #smoother = loessLine
              )
```

```{r ols.plot, eval=FALSE, message=FALSE}
library(olsrr)
ols_plot_cooksd_bar(fit.01)
ols_plot_cooksd_chart(fit.01)
ols_plot_dfbetas(fit.01)
ols_plot_dffits(fit.01)
ols_plot_resid_stud(fit.01)
ols_plot_resid_stand(fit.01)
ols_plot_resid_lev(fit.01)
ols_plot_hadi(fit.01)
ols_plot_resid_pot(fit.01)
```

```{r residuals.plot, eval=FALSE, message=FALSE, results='hide'}
#plot(fit)
#plot(predict(fit), resid(fit), pch= ".")
ggplot(data.frame(x = banksPanel.01$SprEp, y = fit.01$residuals),
       aes(x = x, y = y)) +
  geom_hline(yintercept = 0, size = 2) +
  geom_point(size = 3, colour = "black", alpha = 0.4) +
  geom_point(size = 2, colour = "blue", alpha = 0.4)
```

Entre as variáveis que foram eliminadas estão a participação de mercado ($MkSh$), grau de concentração ($GrCon$), operações de crédito total ($OpCrTotal$), *spread ex-ante* ($SprEa$) e o Índice de preços ao consumidor ($IPCA$), por possuirem elevada correlação com outras variáveis e por não se demonstarrem sigifinicativas em primeira testagem de modelo. 

Foram eliminadas as variáveis *dummy* de controle de capital ($OCap$) e caráter da instituição ($CrIns$), por falta de informações evolutivas. Somente a variável *dummy*  referente à taxonomia ($TpIns$) foi mantida no modelo, esperando que ela venha captar as diferenças operacionais.

O painel de dados foi modificado em algumas variáveis para se adequar a nova modelagem e evitar problemas de autocorrelação. Preliminarmente dos dados monetários foram escalonados para unidades em milhões. Para as variáves referentes a base monetária e meios de pagamentos foram aplicados o logarítimo natural e de forma alternativa para fins de ajustes, considerado a variacação no ao longo do tempo destas variáveis.   

Foram incluídas no modelo varíáveis  para captar as diferenças operacionais indicando a participação das receitas segmentadas em relação as receitas operacionais: receitas de operação de crédito ($ROpCr$), receitas de serviços ($RSrv$), receitas de participações ($RPart$) e outras receitas operacionais ($OtROp$).

Em relação a participação das modalidades de depósitos sobre as operações de créditos totais ($OpCrTot$), além dos dos depósitos a vista ($DepAv$) e depóstos a prazo ($DepAp$),  foram incluídos os depósitos de poupança ($DepPop$), depositos interfinanceiros ($DepIf$) e outros depósitos ($OtDep$). Com objetivos de verificar o perfil de captação por modalidade e como este influencia no nível de *spread*. 

Para a inadimplência ($Inad$) passou-se a usar a participação da provisão para crédito e outros créditos duvidoso sobre a soma das operações de crédito e outros crédito ($OpCrTot$)\footnote{Já adicionados dos próprios valores de provisão que se encontram subtraídos nas demonstrações contábeis}. 

Para captar as diferenças no perfil de despesas por modalidadde de instituições e como este influencia no nível de *spread* além das despesas administrativas em função das operações totais ($DAdm$) foram inclúídas as despesas de captação em função dos depósitos totais ($DesCap$) e outras despesas em função das operações de créditos totais ($OtDes$).

Finalizando os ajuste no modelo, foram incluídas as variáveis de impostos indiretos ($ImpInd$) e imposto de renda ($ImpRen$), completando as variáveis explícitas do *spread*, com exceção do compulsório por apresentar forte correlação com outras variáveis e do do fundo garantidor de crédito por se demonstrar insignificante.

```{r equation.model, eval=TRUE, results='hide'}
library(equatiomatic)
model <- extract_eq(fit.01, 
                    use_coefs = FALSE,
                    wrap = TRUE, intercept = "beta")

print(model)
```

\begin{equation}
\begin{aligned}
\operatorname{SprEp} &= \beta_{0} + \beta_{1}(\operatorname{DAdm}) + \beta_{2}(\operatorname{DesCap}) + \beta_{3}(\operatorname{GrCon})\ + \\
&\quad \beta_{4}(\operatorname{OtDes}) + \beta_{5}(\operatorname{Inad}) + \beta_{6}(\operatorname{Int}) + \beta_{7}(\operatorname{EPr})\ + \\
&\quad \beta_{8}(\operatorname{lnComp}) + \beta_{9}(\operatorname{ImpInd}) + \beta_{10}(\operatorname{ImpRend}) + \beta_{11}(\operatorname{DepAv})\ + \\
&\quad \beta_{12}(\operatorname{DepAp}) + \beta_{13}(\operatorname{DepPop}) + \beta_{14}(\operatorname{OpFin}) + \beta_{15}(\operatorname{OpEmp})\ + \\
&\quad \beta_{16}(\operatorname{ROpCr}) + \beta_{17}(\operatorname{RSrv}) + \beta_{18}(\operatorname{RPart}) + \beta_{19}(\operatorname{SelMet})\ + \\
&\quad \beta_{20}(\operatorname{VelMo}) + \epsilon
\end{aligned}
\end{equation}


```{r gvmla, eval=FALSE, message=FALSE, results='hide'}
library(gvlma)

testgvmla <- gvlma(OSprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp #+ OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
          data = banksPanel.01)
summary(testgvmla)
```

```{r statistics.01}
varInd <- c("SprEp", "DAdm", "DesCap", "GrCon", "OtDes", "Inad",
            "Int", "EPr", "TpIns", "lnComp", "ImpInd", "ImpRend",
            "DepAv", "DepAp", "DepPop", "OpFin", "OpEmp", 
            "ROpCr", "RSrv", "RPart", "SelMet", "VelMo")

mod01Obs <- data.frame(TEMPO = length(unique(banksPanel.01$DATA)),
           OBSERVAÇÕES = length(banksPanel.01$SprEp),
           INSTITUICÕES = length(unique(banksPanel.01$BANCO)),
           "VARIÁVEIS EXPLICATIVAS" = length(varInd)
           ) 

mod01nObs <- mod01Obs$OBSERVAÇÕES
mo01nTemp <- mod01Obs$TEMPO
mo01nIns <- mod01Obs$INSTITUICÕES
```

O painel desenvolvido para a construção dos modelos resultou no total `r mod01nObs` observações, `r mo01nTemp` períodos de tempo, contemplando um total de `r mo01nIns` instituições, flutuando a cada período, conforme \autoref{tb:rsumoobs}, caracterizando-se em um painel não balanceado. 

\begin{table}[!h]
\caption{Resumo de dados do Painel}
```{r statistics.table}
mod01Obs %>% kbl(booktabs = T) %>% 
  kable_styling(latex_options = c("striped"),
                font_size = 10, full_width = T)
```
\label{tb:rsumoobs}
\fonte{Densenvolvido a partir dos dados coletados}
\end{table}

Foi realizado o teste Dick-Fuller para checar a estacionariedade da série, sendo rejeitada a hipótese nula, indicando que é estacionária, conforme indicado na \autoref{tb:dickfuller}.

```{r test.dick.fuller, message=FALSE}
library(tseries)

#######
#6.6.6 Testando raízes unitárias
#O teste de Dickey-Fuller prova se a série é estocástica, 
#a hipótese nula é de que a série possui raiz unitária (não-estacionaridade).
#Desta forma, algumas saídas são possíveis, como a transformação da série ou mesmo a utilização da primeira diferença da série.
#####

adfTest <- adf.test(banksPanel.01$SprEp, 
         alternative = c("stationary", "explosive"),
          k = trunc((length(banksPanel.00$SprEp)-1)^(1/3))) %>% 
        table() %>% as.data.frame() %>% 
        mutate(P.VALOR = p.value, 
               ESTATÍSTICA = statistic,
               PARÂMETROS = parameter,
               ALTERNATIVA = "Estacionária") %>%
        select(ESTATÍSTICA, P.VALOR, PARÂMETROS, ALTERNATIVA)
```

\begin{table}[!hb]
\caption{Resultado do teste Dick-Fuller}
\vspace{1mm}
```{r print.df, message=FALSE, tidy=TRUE}
tbadfTest <- adfTest %>% 
  kbl(booktabs = T) %>% 
  kable_styling(latex_options = "striped",
                font_size = 10, full_width = T)

tbadfTest
```
\vspace{1mm}
\label{tb:dickfuller}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}



```{r graph.adf, eval=FALSE, results='hide'}
#\begin{grafico}[!htbp]
#\vspace{20pt}
#\caption{Visualização }
#\vspace{-4mm}


#diff.model <- diff(banksPanel.02$SprEp) %>% as.data.frame() %>% mutate(Index = row_number())
#colnames(diff.model) <- c("Index", "Diff")

#ggplot(diff.model, aes(x = Index)) + 
#        geom_line(aes(y =  Diff ))


banksPanel.01 %>% group_by(DATA) %>% summarise(OBS = mean(SprEp)) %>% 
        ggplot(aes(x = DATA)) +
        geom_line(aes(y = OBS))

#\vspace{-3mm}
#\label{graf:dickfuller}
#\fonte{Desenvolvido a partir de dados coletados}
#\vspace{-2mm}
#\end{grafico}
```

Os dados em painel foram estimados nos métodos *pooling*, efeitos fixos e efeitos aleatórios, com os resultados demonstrados na \autoref{tb:modpool}, \autoref{tb:modef}, \autoref{tb:intfixef}, \autoref{tb:modrand} e \autoref{tb:modsr2}. 

\begin{table}[!p]
\caption{Resultado Modelo Pooling}
\vspace{1mm}
```{r pooling}
library(plm)

mod01.Pooling <- plm(SprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr + TpIns
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp #+ OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
                   index = c("TpIns"),
                   model = 'pooling',
                   data = banksPanel.01)

summPoo <- mod01.Pooling %>% summary()
summPoo$coefficients %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", 
                full_width = TRUE, font_size = 10) %>%
  column_spec(1, width = "5cm") %>%
  column_spec(2, width = "2cm") %>% 
  column_spec(3, width = "2cm") %>% 
  column_spec(4, width = "2cm") %>% 
  column_spec(5, width = "2cm")
 
```
\vspace{1mm}
\label{tb:modpool}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

\begin{table}[!htb]
\caption{Resultado Modelo Efeitos Fixos}
\vspace{1mm}
```{r fixed.effects}
library(plm)

mod01.FixEf <- plm(SprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp + OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
                   index = c("TpIns"),
                   data = banksPanel.01,
                   model = 'within'
                   #effect = c(#"time",
                        #      "twoways"
                              #"individual"
                         #     )
                   )
summFe <- summary(mod01.FixEf)
summFe$coefficients %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", 
                full_width = TRUE, font_size = 10) %>% 
  column_spec(1, width = "5cm") %>%
  column_spec(2, width = "2cm") %>% 
  column_spec(3, width = "2cm") %>% 
  column_spec(4, width = "2cm") %>% 
  column_spec(5, width = "2cm")
```
\vspace{1mm}
\label{tb:modef}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}


\begin{table}[!hbtp]
\caption{Interpectos do modelo de Efeitos Fixos}
\vspace{1mm}
```{r table.interccep}
summary(fixef(mod01.FixEf)) %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10) %>%   column_spec(1, width = "5cm") %>%
  column_spec(2, width = "2cm") %>% 
  column_spec(3, width = "2cm") %>% 
  column_spec(4, width = "2cm") %>% 
  column_spec(5, width = "2cm")
```
\vspace{1mm}
\label{tb:intfixef}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

\begin{table}[!p]
\caption{Resultado Modelo Efeitos Aleatórios}
\vspace{1mm}
```{r random.effects}

library(plm)

mod01.RanEff <- plm(SprEp ~ DAdm + DesCap + GrCon + OtDes
          + Inad #+ RcPd 
          + Int + EPr + TpIns
          + lnComp + ImpInd + ImpRend
          + DepAv + DepAp + DepPop 
          + OpFin + OpEmp #+ OtOp 
          + ROpCr + RSrv + RPart
          + SelMet + VelMo,
                      data = banksPanel.01,
                    index = c("TpIns"),
                      model = 'random', 
                    random.method  = "walhus"
                      )
summRand <-  mod01.RanEff %>% summary()
summRand$coefficients %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", 
                full_width = TRUE, 
                font_size = 10) %>% 
  column_spec(1, width = "5cm") %>%
  column_spec(2, width = "2cm") %>% 
  column_spec(3, width = "2cm") %>% 
  column_spec(4, width = "2cm") %>% 
  column_spec(5, width = "2cm")
```
\vspace{1mm}
\label{tb:modrand}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Resultado de coeficiente de determinação para os modelos}
\vspace{1mm}
```{r rsqr}
pooR2 <- summPoo$r.squared %>% as.data.frame()
fixR2 <- summFe$r.squared %>% as.data.frame()
randR2 <- summRand$r.squared %>% as.data.frame()

data.frame(Modelos = c("Pooling", "Efeitos Fixos", 
                            "Efeitos Aleatórios"),
           "R.2" = c(pooR2[1,1], fixR2[1,1], randR2[1,1]),
           "R Ajustado" = c(pooR2[2,1], fixR2[2,1], randR2[2,1])) %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)
```
\vspace{1mm}
\label{tb:modsr2}
\fonte{Desenvolvido a partir dos dados coletados}
\vspace{-2mm}
\end{table}

```{r tables.models, results='hide'}
library(pander); library(apsrtable); library(huxtable); library(stargazer)

stargazer(mod01.Pooling, mod01.FixEf, mod01.RanEff, 
          column.labels = c("Pooling", "Efeitos Fixos", 
                            "Efeitos Aleatórios"),
          label = "tb:regress",
          type = "latex", 
          title = "Resultados das Regressões", 
          header = FALSE,
          single.row = TRUE,
          align = TRUE, 
          style = "all", 
          keep.stat = c("aic", "bic", "rsq", 
        "adj.rsq", "n"))
```


```{r some.tests, eval=FALSE, include=FALSE}

robPolling <- coeftest(mod01.Pooling, vcov.=vcovHC(mod01.Pooling, method = c("arellano")))
robPolling

robFixEf <- coeftest(mod01.FixEf, vcov.=vcovHC(mod01.FixEf, method = c("arellano")))
robFixEf

robRanEff <- coeftest(mod01.RanEff, vcov.=vcovHC(mod01.RanEff, method = c("arellano")))
mod01.RanEff

summary(mod01.Pooling, vcov = function(x) vcovHC(mod01.Pooling, method = "arellano"))

####colinearidade 
bptest(mod01.Pooling); bptest(mod01.FixEf); bptest(mod01.RanEff); bptest(fit)

####autocorrelacionado com os erros
resPooling <- as.vector(mod01.Pooling$residuals)
durbinWatsonTest(resPooling); durbinWatsonTest(mod01.FixEf$residuals); durbinWatsonTest(fit.2)

#leveragePlots(fit.02)
```

No modelo *pooling*, não foi encontrada significância a 5%, para as variáveis de meios de pagamentos ($M4$), velocidade da moeda ($VelMo$), impostos indiretos ($ImpInd$) e depositos a vista ($DepAv$). As demais variáveis apresentação elevado nível de significância. Foi aplicado o teste de Wooldridge aceitando a hipótese nula que os erros para a taxonomia não são relacionados.  

Foi utilizado o teste Wooldridge para o modelo *pooling* para checar a correlacão nos erros no grupo de taxonomia. O resultado do teste conforme \autoref{tb:wdtest} aceita a hipotese nula, indicando que os entre o grupo avaliado não é correlacionado.

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Resultado do teste Wooldridge para o modelo pooling}
\vspace{1mm}
```{r test.Wooldridge}
### 6.6.5 Teste para efeitos individuais ou de tempo

## para modelos pooling
##A hipótse nula é a não correlação entre os erros do mesmo grupo
## p value menor que 5% rejeita a hipotese nula - tendo correlacao
library(pander)
wt.pooling <- pwtest(mod01.Pooling)

data.frame(Estatística = wt.pooling$statistic,
           Valor.P = wt.pooling$p.value,
           "Hipótese Alternativa" = "Correlação nos Erros") %>% 
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)

#wt.pool.time <- pwtest(mod01.Pooling, effect = "time")
# rejeita a hipotese nula - há correlação do efeito tempo
```
\vspace{1mm}
\label{tb:wdtest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}


```{r test.durbin.watson, results='hide', message=FALSE, eval=FALSE}
library(lmtest)

dwtest(formula = SprEp ~ lnOpTot + lnROp #+ lnAtv #+ lnOpCrMkt 
                    + DAdm + DesCap + OtDes #+ RcPd
                    + Inad #+ OpCr + OpFin + OtOp
                    + SelMet + VelMo + ImpRend  #+ ImpInd
                    + DepAv + DepAp #+ DepIf + DepPop
                    + ROpCr + RSrv + RPart,
                      data = banksPanel.00, 
       order.by = NULL, alternative = c("greater", "two.sided", "less"),
       iterations = 15, exact = NULL, tol = 1e-10)

```

Para comparação entre os modelos pooling e efeitos fixos foi aplicado o teste F de Chrow para avaliar os efeitos individuais, sendo rejeitada a hipótese nula de igualdade nos interceptos e coeficientes, indicando que o modelo de efeitos fixos seria mais adequado para estimação do modelo. 

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Teste F para igualdade nos interceptos e inclinações}
\vspace{1mm}
```{r test.pool.fe, message=FALSE}
### TESTS Modelo Pooled x Modelo de Efeitos Fixos
### test f de chrow
### hipotese nula é de igualdade nos interceptos e nas inclinacoes para o os individuos indicando o modelo pooled

pFtest <- pFtest(mod01.Pooling, mod01.FixEf)

data.frame(Estatística = pFtest$statistic,
           DF01 = pFtest$parameter[1],
           DF02 = pFtest$parameter[2],
           P.Valor = pFtest$p.value, 
           Hipótese.Alternativa = "Não Igualdade nos Interceptos") %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)

# p menor que 0.05 indica que efeitos fixos é melhor 
```
\vspace{-1mm}
\label{tb:pftest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

Para comparar os modelos pooling e efeitos aleatórios foi utilizado o teste Breusch-Pagan (multiplicador de lagrange) para modelos em painel não balanceados, aceitando a hipótese nula que a variância dos erros são iguais, indicando homocedasticidade.  

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Teste Breusch-Pagan para variâncoa dos erros em painéis desbalanceados}
\vspace{1mm}
```{r test.poo.randeff}
####TEST Modelo Pooled x Modelo de Efeitos Aleatórios

### aceitação da hipotese nula implica que pooled é melhor
### p valor menor que 5% rejeita hipotese nula e indica que efeitos aleatorios é prefeível 

plmtest <- plmtest(mod01.Pooling, type = "bp")

data.frame(Estatística = plmtest$statistic,
           Df = plmtest$parameter,
           P.Valor = plmtest$p.value,
           Alternativa = "Variância dos Erros") %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)
```
\vspace{-1mm}
\label{tb:lbptest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

Em termos de comparação entre os modelos de efeitos fixos e efeitos aleatórios foi utilizado o teste de Hausman, com rejeição da hipotese nula (parâmetros não correlacionados), indicando assim correlação entre os parâmetros e indicando que o modelo e efeitos fixos é mais adequado para avaliação do modelo.   

\begin{table}[!hbtp]
\caption{Teste Hausman para correlação dos parâmetros}
\vspace{1mm}
```{r test.fix.random}
## tests Modelo Efeitos Fixos x Modelo de Efeitos Aleatórios

## rejeitar a hipotese nula implica que efeitos fixo  é mais adequado 

##p valor menor que 5% rejeita hipotese nula (indicando que os parâmetros são correlacionados) indicando que efeitos fixos é mais adequado

## p valor maior que 5% aceita hipotese nula (indica que os parâmetros não sao correlacionados) indicando que o modelo de efeitos aleatorios é melhor

phtest <- phtest(mod01.FixEf, mod01.RanEff)

data.frame(Estatística = phtest$statistic,
           DF = phtest$parameter,
           Valor.P = phtest$p.value,
           Alternativa = "Correlação nos Parâmetros") %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = T, font_size = 10)


```
\vspace{-1mm}
\label{tb:htest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

Para checar a dependência transversal do modelo de efeitos fixo foi utilizado o teste Pesaran, sendo rejeitada a hipótese nula (não correlação dos resíduos aos indivíduos) indicando que os resíduos entre os individuos estão correlacionados.

\begin{table}[!hbtp]
\caption{Teste Persan CD para dependência transversal}
\vspace{1mm}
```{r pcdtest}
##### 
#Testando dependência transversal (cross-sectional)
#A dependência cross-sectional se apresenta em panieis com longas séries de tempo. 
#A hipótese nula é de que os resíduos através dos indivíduos não estão correlacionados.  teste de Pesaran (2015):
#####


pcdtest.pool <- pcdtest(mod01.Pooling, ttest = "cd")
pcdtest.fix <- pcdtest(mod01.FixEf, ttest = "cd")
pcdtest.rand <- pcdtest(mod01.RanEff, ttest = "cd")

data.frame(Modelo = c("Pooling",  "Efeitos Fixos", "Efeitos Aleatórios"),
           Estatística = c(pcdtest.pool$statistic, pcdtest.rand$statistic,
                           pcdtest.fix$statistic),
           Valor.P = c(pcdtest.pool$p.value, pcdtest.fix$p.value,
                          pcdtest.rand$p.value),
           Alternativa = rep("Correlação nos resíduos dos indivíduos",3)
           ) %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = TRUE, font_size = 10)


```
\vspace{-1mm}
\label{tb:pcdtest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}


A normalidade dos resíduos os três modelos foi testado pelo método Shapiro-Wilk, rejeitando a hipótese nula de normalidade dos resíduos, indicando que os modelo apresenta problemas de hetetocedasticidadade. 

\begin{table}[!hbtp]
\caption{Teste Shapiro-Wilk para normalidade dos resíduos}
\vspace{1mm}
```{r shapiro.test}
##Normalidade dos resíduos

shap.pool <- shapiro.test(mod01.Pooling$residuals[1:500])

shap.fix <- shapiro.test(mod01.FixEf$residuals[1:500])

shap.rand <- shapiro.test(mod01.RanEff$residuals[1:500])

data.frame(Modelo = c("Pooling",  "Efeitos Fixos", "Efeitos Aleatórios"),
           Estatística.W = c(shap.pool$statistic, shap.fix$statistic,
                             shap.rand$statistic),
           Valor.P = c(shap.pool$p.value, shap.fix$p.value,
                             shap.rand$p.value)
           ) %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = TRUE, font_size = 10)

```
\vspace{-1mm}
\label{tb:swtest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

A normalidade dos resíduos do modelo de efeitos aletórios foi testado pelo método, rejeitando a hipótese nula de normalidade dos resíduos, indicando que o modelo apresenta problemas de hetetocedasticidadade. 

\begin{table}[!hbtp]
\caption{Teste Breusch-Pagan estudentizado para normalidade dos resíduos em efeitos aleatórios}
\vspace{1mm}
```{r test.final.model}
library(lmtest)

bptest.pool <- bptest(mod01.Pooling) 
bptest.fix <- bptest(mod01.FixEf) 
bptest.rand <- bptest(mod01.RanEff)

data.frame(Modelo = c("Pooling", "Efeitos Fixos", "Efeitos Aleaórios"),
           Estatística = c(bptest.pool$statistic, bptest.fix$statistic,
                           bptest.rand$statistic),
           Valor.P = c(bptest.pool$p.value, bptest.fix$p.value, 
                       bptest.rand$p.value)
           ) %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = TRUE, font_size = 10)


### Homocedasticidade dos resíduos
## hipotese nula que há homocedasticidade
## p value menor que 5% indica que a hipoteses nula é rejeitada e há problemas no resíduos da regressão e problema de heterocedasticidade
## pode ser resolvido com transformacão de variaveis

```
\vspace{-1mm}
\label{tb:sbptest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

Foi testada a correlação serial do modelo de efeitos fixos, rejeitando a hipotese nula (de não correlação serial), indicando assim que o painel de dados possui problemas de correlação serial entre dos dados. 

\begin{table}[!hbtp]
\caption{Teste Breusch-Godfrey/Wooldridge para correlação serial}
\vspace{1mm}
```{r pbgtest}
## Testando correlação serial
#hipótese nula, ou seja, não há problemas de correlação serial nos dados
# valor maior que 5% aceita hipotese nula, de que não há problemas de correlação serial 


pbgtest.pool <- pbgtest(mod01.Pooling)
pbgtest.fix <- pbgtest(mod01.FixEf)
pbgtest.rand <- pbgtest(mod01.RanEff)


data.frame(Modelos = c("Pooling", "Efeitos Fixos", "Efeitos Aleaórios"),
           Estatística = c(pbgtest.pool$statistic, pbgtest.fix$statistic,
                           pbgtest.rand$statistic),
           DF = c(pbgtest.pool$parameter, pbgtest.fix$parameter,
                  pbgtest.rand$parameter),
           Valor.P = c(pbgtest.pool$p.value, pbgtest.fix$p.value,
                       pbgtest.rand$p.value),
           Alternativa = rep("Correlação serial no erros indissiocráticos",3)
           ) %>% kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", full_width = TRUE, font_size = 10)
  
```
\vspace{-1mm}
\label{tb:bgwtest}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\end{table}

Os resultados das estimações dos modelos, demonstraram elevada siginificância para as variáveis, com coeficientes de determinação acima em torno de 95%, porém os testes indicaram problemas de heterocedasticidade e correlação serial dos dados, podendo estar inflando os resultados, demonstrando-se inadequados para uma estimação confiável. 

Porém, de acordo com Sargan (1964) e Hendry e Mizon (1978), os testes de dependência cross-seccional e correlação serial não significam essencialmente que exista essa condição para o modelo, e sim um problema de especificação dinâmica, com a omissão de variáveis defasadas. 

O modelo conceitual e economético desenvolvido está regido pelo dinamismo econômico, com uma variável dependente obtida através da diferença de dois termos de resultados, afetada pela combinação de relações entre as variáveis microecnômicas endógenas e de mercado, e de variáveis macroeconômicas, necessitando assim de uma modelagem que comporte esse dinamismo.

Diante as características do modelo, foi identificada a metodologia de painel de vetores autoregressivos (PVAR), que comporta mais de uma variável dependente defasadada, variáveis preditoras endógenas e variáveis preditoras exógenas com estimação por método de momentos generalizados (GMM) . 

A metodologia PVAR mostra-se compatível com a característica de painel não balanceado (N > T), porém necessitando de tratamento em observações inciais, e enfretando problemas com a questão da heterogeneidade entre os grupos de cortes transversais. Tais limitações seriam contornadas com a utilização do método GMM (\uppercase{Newey e Rosen} 1988). 

O modelo de estimação por GMM proposto por Arellano e Bond (1991), vem contornar a incosistência dos modelos de efeitos fixos, utilizando variáveis defasadas como instrumentos para variáveis endógenas. O procedimento de estimação pode ser em uma etapa, ou duas etapas, onde esta se basea nos resíduos da primeira etapa, e uma matriz é utilizada para retirar o modelo de efeito fixo.  

No modelo PVAR-GMM proposto por Arellano e Bond (1991) se alguma variável possuir raiz unitária, o estimador será inconsistente. Porém, de acordo com Binder, Hsiao e Pesaran (2005), seria mais eficiente do que estimar cada equação por GMM. Tal limitação seria contornada pela proposta de uma sistema GMM apresentado por Blundell e Bond (1998). 

A proposta de Blundell e Bond (1998) consiste corrigir o viés causado pelos efeito fixos aplicados em painéis dinâmicos, através da modificação, ou seja, a retirada em primeira ordem, dos instrumentos, passando a serem exógenos aos efeitos fixos, assumindo que as variações nas variáveis instrumentais não são correlacionadas com os efeitos fixos e com o erro. 

Nesse sentido painel será estimado através da técnica de Painel de Vetores Autoregressivos (PVAR) com estimação Método de Momentos Generalizados (GMM), em uma etapa, com transformação *Forward orthogonal deviations* (FOD).

O novo painel foi desenvolvido com a eliminação de variáveis que ainda apresentavam  nível de correlação considerado elevado para a metodologia. As variáveis de *spread ex-post* ($SprEp$) e rentabilidade ($Rent$) foram inseridas simultaneamente no modelo como depedentes, as variáveis micreconômicas foram inseridas como preditoras e as variáveis macroeconômicas foram inseridas como exógenas.

```{r pvargmm.dynamic, eval=FALSE, message=FALSE, results='hide'}
library(panelvar)
#detach(package:splines, unload = TRUE)

saveRDS(banksPanel, file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.RDS")

saveRDS(banksPanel.00, file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.00.RDS")

saveRDS(banksPanel.01, file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.01.RDS")


banksPanel <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.RDS")

banksPanel.00 <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.00.RDS")

banksPanel.01 <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/banksPanel.01.RDS")



Id_Data <- banksPanel.01 %>% group_by(DATA) %>% summarise(Id_Data = 1:length(unique(DATA))) %>% mutate(Id_Data = row_number())

Id_Banks <- banksPanel.01 %>% group_by(BANCO) %>% summarise(Id_Banco = 1:length(unique(BANCO))) %>% mutate(Id_Banco = row_number())

Id_TpIns <- banksPanel.01 %>% group_by(TpIns) %>% summarise(Id_TpIns = 1:length(unique(TpIns))) %>% mutate(Id_TpIns = row_number()) 

obs.panel <- banksPanel.01 %>% 
  group_by(BANCO) %>% 
  summarise(OBS = sum(length(BANCO))) %>% select(BANCO, OBS)

model.pvrgmm <- 
        banksPanel.01 %>%
        left_join(Id_Data, by = "DATA") %>% 
        left_join(Id_Banks, by = "BANCO") %>% 
        left_join(Id_TpIns, by = "TpIns") %>%
        left_join(obs.panel, by = "BANCO") %>%
        mutate(DATA = as.factor(DATA)) %>%
        na.omit() %>%
        select("DATA", "SprEp", "TxApl", "TxCap", "BANCO", "Rent", "DAdm",
               "DesCap", "OtDes", "Inad", "RcPd", "Int", "EPr", "DepAv",
               "DepAp", "DepPop", "ROpCr", "RSrv", "RPart", "OpEmp", "OpFin",
               "OtOp",  "ImpInd", "ImpRend",  "SelOvr", "VelMo", "Comp",
               "GrCon", "Id_Banco", "Id_Data", "Id_TpIns", "OSprEp", 
               "IPCA", "lnBMR", "lnOpCrMkt", "SelOvr", "lnMPA2", "lnComp",
               "lnOpTot", "lnAtv", "lnROp", "SelMet", "TitPub", "lnBMA"
          ) %>% 
        as.data.frame()

saveRDS(model.pvrgmm, file = "~/Desktop/04-DISSERTATION/01-data/model/model.pvrgmm.RDS")


model.pvrgmm <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/model.pvrgmm.RDS")

library(caret)
set.seed(1234)
pvar.train <- createDataPartition(model.pvrgmm$SprEp, p = .10, list = FALSE)

pvar.gmm.train <- model.pvrgmm[pvar.train,]
pvar.gmm.test <- model.pvrgmm[-pvar.train,]

pvar.gmm.test %>% dim()
pvar.gmm.train %>% dim()

#cols <- pure.panel %>% select(-DATA, -BANCO, -TAXONOMIA, -CNPJ, -NOME_INSTITUICAO, -TpIns) %>% colnames()

#cols <- cols[1:202]
#endo <- cols

depVar <- c(
            "SprEp",
            #"TxApl",
            #"TxCap"
            "Rent"
            )

endo <- c("DAdm", "DesCap", "OtDes",
          "Inad",  "RcPd", 
          #"Int",
          "EPr", 
          "DepAv", "DepAp", "DepPop",
          "ROpCr", "RSrv", "RPart",
          "OpEmp", "OpFin", "OtOp", 
          "ImpInd", "ImpRend"
          #"lnOpTot", "lnAtv", "lnROp"
          )

exo <- c(
          "SelOvr",
          "VelMo",
          "Comp",
          "GrCon",
          "IPCA",
          "lnBMA",
          "lnOpCrMkt"
         )

fit.pvargmm <-  
        pvargmm(dependent_vars = depVar,
                lags = 2,
                predet_vars = endo,
                exog_vars = exo,
                transformation = "fod",
                data = model.pvrgmm,
                panel_identifier = c("BANCO", "DATA"),
                steps = c(
                          #"onestep"
                          "twostep"
                          ),
                system_instruments = TRUE, # HABILITADO FALSE
                system_constant = FALSE, # DESABILITADO  TRUE
                pca_instruments = TRUE, # DESABILITADO FALSE
                pca_eigenvalue = 1, #DESABILITADO - 1
                max_instr_dependent_vars = 99,
                max_instr_predet_vars = 99,
                min_instr_dependent_vars = 2L,
                min_instr_predet_vars = 1L,
                collapse = TRUE,
                #tol = 1e-09,
                progressbar = TRUE
 )

sumPvarGmm <- summary(fit.pvargmm)

saveRDS(fit.pvargmm,  file = "~/Desktop/04-DISSERTATION/01-data/model/fit.pvargmm.RDS")
  
saveRDS(sumPvarGmm,  file = "~/Desktop/04-DISSERTATION/01-data/model/sumPvarGmm.RDS")
```

```{r read.pvargmm}
fit.pvargmm <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/fit.pvargmm.RDS")

sumPvarGmm <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/sumPvarGmm.RDS")
```

Em teste preliminar a estimação em PVAR-GMM, conforme a \autoref{tb:pvargmm}, com 40% dos dados remontou resultados inconsistente com aceitação da hipótese nula através do teste Chi-Quadrado.

Para o *Spread Ex-Post* foi remontada siginificância para a Spread Ex-Post e Rentabilidade desasados, Despesas adminstrativas, Despesas de Captação, Outras Despesas, Inadimplência, Risco de crédito, Intagível, Capital Próprio, Depósitos a vista, Receita de participação, Operações de Financiamento, Imposto de Renda, Selic Over e Velociadade da Moeda.

No teste preliminar, das variáveis componentes do Spread Ex-Post, foi encontrada siginificância sobre a Rentabilidade a o spread e a própria rentabilidade defasados, Despesas Administrativas, receitas de serviços e imposto de renda.

\vspace{20pt}
\captionof{table}{Resultado do modelo PVAR-GMM}
\vspace{-1mm}
```{r table.pvargmm, eval=FALSE}
#sumPvarGmm
#tb.pvargmm <- panelvar::knit_print.pvarfeols(fit.pvargmm)
```

\vspace{1mm}
\label{tb:pvargmm}
\fonte{Desenvolvido a partir dos dados estimados}
\vspace{-2mm}
\vspace{20pt}

\parindent 1.50cm

A \autoref{tb:mmsc} demonstra o resultado dos testes Andrews_Lu_MMSC, revelando a inconsistência do modelo (até o momento), porém indicando que ainda é matematicamente possível. 

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Testes MMSC para modelo PVAR-GMM}
\vspace{-1mm}
```{r test.andrews}
library(panelvar)
Andrews_Lu_MMSC(fit.pvargmm, HQ_criterion = 2.1) %>% as.data.frame() %>% 
  kbl(booktabs = TRUE) %>% 
  kable_styling(latex_options = "striped", 
                full_width = T, font_size = 10)
```
\vspace{1mm}
\label{tb:mmsc}
\fonte{Desenvolvido com resultados do modelo}
\vspace{-2mm}
\end{table}

```{r stability}
st.pvar.gmm <- stability(fit.pvargmm)
```

O \autoref{graf:stability} traz a visualização do teste de estabilidade do modelo, demonstrando que é atendida as condições de estabilidade, uma vez que todos os autovalores estão dentro do círculo unitário.

\begin{grafico}[!hbtp]
\vspace{20pt}
\caption{Gráfico de estabilidade do modelo PVAR GMM}
\vspace{-4mm}
```{r stability.plot}
plot(st.pvar.gmm)
```
\vspace{-3mm}
\label{graf:stability}
\fonte{Desenvolvido a partir de dados coletados}
\vspace{-2mm}
\end{grafico}

\vspace{20pt}

\begin{table}[!hbtp]
\caption{Teste J Hansen para modelo PVAR-GMM}
\vspace{-1mm}
```{r hansen.test, eval=TRUE}

# H0: restrições de superidentificação são válidas
# A hipótese nula do teste implica que todos os instrumentos são válidos
#O valor de p maior que 5% (0,05) implica, aceitamos o Ho, ou seja, todos os instrumentos são válidos.

hansen_j_test(fit.pvargmm) %>% as.data.frame() %>% 
  kbl(booktabs = TRUE) %>%
  kable_styling(latex_options = "striped", full_width = TRUE)
```
\vspace{1mm}
\label{tab:hansen}
\fonte{Desenvolvido a partir dos resultados do modelo}
\vspace{-2mm}
\end{table}

```{r test.othog, eval=FALSE, results='hide', include=FALSE}
#fevd_orthogonal(fit.pvargmm) %>% table()
```

```{r tests.pvargmm, eval=FALSE, results='hide', include=FALSE}
###tests
#extract(fit.pvargmm)

oirf <- oirf(fit.pvargmm, n.ahead = 2)

girf <- girf(fit.pvargmm, n.ahead = 2, ma_approx_steps= 2)

#pvalue(fit.pvargmm)

bs <-
  bootstrap_irf(
    model = fit.pvargmm,
    typeof_irf = c("GIRF"),
    n.ahead = 2,
    nof_Nstar_draws = 10,
    confidence.band = 0.95
)
  
saveRDS(oirf, file = "~/Desktop/04-DISSERTATION/01-data/model/oirf.RDS")
saveRDS(girf, file = "~/Desktop/04-DISSERTATION/01-data/model/girf.RDS")
saveRDS(bs, file = "~/Desktop/04-DISSERTATION/01-data/model/bs.RDS")

```

No \autoref{graf:impulse} será demonstrada a função impulso-respo

\vspace{20pt}

\begin{grafico}[!htbp]
\caption{Função de impulso resposta generalizado}
\vspace{-4mm}
```{r impulse.plot}
#oirf <- readRDS("~/Desktop/04-DISSERTATION/01-data/model/oirf.RDS")
#girf <- readRDS(girf, 
#                file = "~/Desktop/04-DISSERTATION/01-data/model/girf.RDS")


oirf <- oirf(fit.pvargmm, n.ahead = 2)

girf <- girf(fit.pvargmm, n.ahead = 2, ma_approx_steps= 2)

bs <- readRDS(file = "~/Desktop/04-DISSERTATION/01-data/model/bs.RDS")

plot(girf, bs)

```
\vspace{-3mm}
\label{graf:impulse}
\vspace{-2mm}
\fonte{Desenvolvido a partir dos resultados do modelo }
\end{grafico}



```{r gmm:gmm, eval=FALSE, results='hide', include=FALSE}

library(gmm)

 gmm(g,x,t0=NULL,gradv=NULL, type=c("twoStep","cue","iterative"),
        wmatrix = c("optimal","ident"), vcov=c("HAC","MDS","iid","TrueFixed"),
kernel=c("Quadratic Spectral","Truncated", "Bartlett", "Parzen", "Tukey-Hanning"), crit=10e-7,bw = bwAndrews, prewhite = 1, ar.method = "ols", approx="AR(1)",
tol = 1e-7, itermax=100,optfct=c("optim","optimize","nlminb", "constrOptim"),
        model=TRUE, X=FALSE, Y=FALSE, TypeGmm = "baseGmm", centeredVcov = TRUE,
        weightsMatrix = NULL, traceIter = FALSE, data, eqConst = NULL,
        eqConstFullVcov = FALSE, mustar = NULL, onlyCoefficients=FALSE, ...)
    evalGmm(g, x, t0, tetw=NULL, gradv=NULL, wmatrix = c("optimal","ident"),
        vcov=c("HAC","iid","TrueFixed"), kernel=c("Quadratic Spectral","Truncated",
        "Bartlett", "Parzen", "Tukey-Hanning"),crit=10e-7,bw = bwAndrews,
        prewhite = FALSE, ar.method = "ols", approx="AR(1)",tol = 1e-7,
        model=TRUE, X=FALSE, Y=FALSE,  centeredVcov = TRUE, weightsMatrix = NULL,
        data, mustar = NULL)



```

```{r pgmm.plm, eval=FALSE, results='hide', include=FALSE}
#### PVAR GMM DYNIMIC PANEL
model.pgmm <- 
        pgmm(formula = SprEp ~ lnOpTot | DepAv | DepAp | DepIf | DepPop,
      data = model.pvrgmm,
      #subset = c(TpIns),
      #na.action,
      effect = c("twoways"
                 #, "individual"
                 ),
      model = c(
              #"onestep"
                "twosteps"
                ),
      collapse = TRUE,
      #$lost.ts = 1,
      transformation = c(
              "d" 
              #"ld"
              ),
      fsm = NULL,
      index = c("TpIns"),
      robust = TRUE,
      time.dummies = TRUE,
      digits = 4,
      width = 100
)

moddel.pgmm %>% summary()

```

```{r kfold, message=FALSE, eval=FALSE, results='hide', include=FALSE}
library(caret)
library(kernlab)

kfInTrain <- createDataPartition(banksPanel$SprEp, p = 0.60, list = FALSE)

kfTraining <- banksPanel[kfInTrain,]
khTesting <- banksPanel[-kfInTrain,]

set.seed(32323)
kfFolds <- createFolds(y = banksPanel$SprEp, k = 10,
                       list = TRUE, returnTrain = TRUE)

sapply(kfFolds, length)

kfFolds[[1]][1:10]

set.seed(32323)
kfResample <- createResample(y = banksPanel$SprEp, 
                             times = 10,
                             list = TRUE)
sapply(kfResample, length)

kfResample[[1]][1:10]

set.seed(32323)

kfSlices <- createTimeSlices(y = banksPanel$SprEp,
                             initialWindow = 20,
                             horizon = 10)
names(kfSlices)

kfSlices$train[[1]]
kfSlices$test[[1]]

kfTraining$SelMet

kfTraining$`81100008` %>% view()

set.seed(1225)
kfModelFit <- train(SprEp ~ log(`16000001`) + log(`71100001`) + log(`41000007`) +
                            `81100008` + SelMet + `16900008` +
                            log(`31000000`) + `21000003` + Tam + 
                            `71700009` + 
                            log((`71000008` -  `71700009` - `71100001`)) +
                            `81700006` + `49100002` +  
                            log(BMA) + GrCon,
                    data = kfTraining, method = "lm")
kfModelFit %>% summary()

install.packages("ISLR")
library(ISLR)

featurePlot(x = kfTraining, y = kfTraining$SprEp,
            c("`16000001`", "`71100001`", "`41000007`", "`81100008`"),
            plot = "pairs")


```

```{r statistic.analisys, eval=FALSE, results='hide', include=FALSE}

#CHART CORRELATION
model.01 %>% select(-DATA, -BANCO, -TpIns) %>% chart.Correlation()

fit2 <- predict(fit.mod01, newdata = model.01.test)
model.01.test

model.02$Rent

library(AER)
require(plm)

my_fn <- function(data, mapping, method="loess", ...){
      p <- ggplot(data = data, mapping = mapping) + 
      geom_point() + 
      geom_smooth(method=method, ...)
      p
    }

ggpairs(model.01[,-1:-2], lower = list(continuous = my_fn))

banksPanel$SprEp %>% summary()


```

```{r kmeans, eval=FALSE, results='hide', include=FALSE}
library(stats)
library(factoextra)

km.model <- banksPanel %>% 
        left_join(Id_Banks) %>% 
        left_join(Id_Data) %>% 
        left_join(Id_TpIns) %>% 
        select(SprEp, Inad ,DAdm ,DesCap ,OtDes, lnOpCrTotal , SelMet ,
               lnMPA4 ,VelMo, MkSh, DepAv ,DepAp ,DepIf ,OtDep, Tam,
               lnOpCr ,lnOtCr ,EPr ,Inv ,ImpRend ,PrtLc ,GrCon, ROpCr ,RSrv,
               RPart , OtROp ,RcPd ,Int, Id_Data, Id_Banco, Id_TpIns)

km.model$Id_TpIns %>% class()
kmeans.model %>% str()

### DEFININDO O NÚMERO IDDEAL DDE CLUSTERS

n.clusters <- fviz_nbclust(km.model, FUNcluster = kmeans)


###Computing k-means clustering

set.seed(123)
km.res <- kmeans(km.model, 2, nstart = 25)
print(km.res)

aggregate(km.model, by=list(cluster=km.res$cluster), mean)


dd <- cbind(km.model, cluster = km.res$cluster)
dd

###Accessing to the results of kmeans() function

head(km.res$cluster, 4)

km.res$size
km.res$centers
getwd()

?fviz_cluster()

###Visualizing k-means clusters
gg <- fviz_cluster(object = km.res, data = km.model,
                   choose.vars = c("SprEp", "SelMet", "Inad"s),
             ggtheme = theme_minimal(),
             labelsize = 7,
             pointsize = .5)
print(gg)
```

```{r modelo.01, message=FALSE, eval=FALSE, results='hide', include=FALSE}
varDep.m1 <- "SprEp"
varDep.m2 <- "LcLq"

varInd <- c("EPr", "EAv", "EAp", 
            "DAdm", "Inad", "Comp",
           #"Vol", 
           "Tam", 
            #"MkSh", 
            "Rent",
            #"Rc", 
            "TpIns", 
            "RcSrv",
            "SprEa", "Cx",# "Rent",
            #"IPCA", 
            "SelMet", #"MPA4", "MPA2",  "BMR",
            #"SelOvr", #"BMA", 
            "GrCon", "VelMo" 
            )

varInds <- paste("EPr", "EAv", "EAp", 
            "DAdm", "Inad", "Comp",
            #"Vol", 
            "Tam", 
            #"MkSh", 
            "Rent",
            #"Rc", 
            "TpIns", 
            "RcSrv",
            "SprEa", "Cx",# "Rent",
            #"IPCA", 
            "SelMet", #"MPA4", "MPA2",  "BMR",
            #"SelOvr", #"BMA", 
            "GrCon", "VelMo",
            sep = " + ")

mod01Fomula <- paste(varDep.m1, varInds, sep = " ~ ")
mod02Fomula <- paste(varDep.m2, varInds, sep = " ~ ")

model.01 <- banksPanel %>% 
        select(DATA, BANCO, 
               combine(varDep.m1, varInd))

model.02 <- banksPanel %>% 
        select(DATA, BANCO, 
               combine(varDep.m2, varInd))
```

```{r training, eval=FALSE, results='hide', include=FALSE}

##### CONFIDENCE INTERVAL 

fit.interval <- plm(SprEp ~ DAdm + Tam + Inad, data = banksPanel)
sumCoef <- summary(fit.interval)$coefficients
sumCoef
sumCoef[1,1] + c(-1,1) * qt(.975, df = fit.interval$df) * sumCoef[1,2]
sumCoef[2,1] + c(-1,1) * qt(.975, df = fit.interval$df) * sumCoef[2,2]
sumCoef[3,1] + c(-1,1) * qt(.975, df = fit.interval$df) * sumCoef[3,2]


### MULTIVARIABLE REGRESSION 

n = 100; x = rnorm(n); x2 = rnorm(n); x3 = rnorm(n)
y = 1 + x + x2 + x3 + rnorm(n, sd = 0.1)
ey = resid(lm(y ~ x2 + x3))
ex = resid(lm(x ~ x2 + x3))
coef(lm(y ~ x + x2 + x3))

require(datasets); data("swiss"); ?swiss; require(GGally)
library(GGally)

my_fn <- function(data, mapping, method="loess", ...){
      p <- ggplot(data = data, mapping = mapping) + 
      geom_point() + 
      geom_smooth(method=method, ...)
      p
    }

ggpairs(model.01[,-1:-2], lower = list(continuous = my_fn))
summary(lm(Fertility ~ ., data = swiss)) #$coefficients

summary(lm(SprEp ~ . , data = model.01[,-1:-2])) #$coefficients

swiss
ggplot(swiss, aes(x = Agriculture, y = Fertility, color = Education)) +
        geom_point(color = "grey50", size = 5) + 
        geom_smooth(method = lm, se = FALSE, color = "black") + 
        geom_point(size = 4)

# VARIÁVEIS DUMMY

library(datasets); data("InsectSprays"); library(stats)

ggplot(InsectSprays,  aes(y = count, x = spray, fill= spray))+ 
        geom_violin(colour = "black",size= 2) + 
        xlab("Type") + ylab("Insect count")

summary(lm(count ~ spray, data = InsectSprays))#$coefficients

summary(lm(count ~
                   I(1 * (spray == "B")) + I(1 * (spray == "C")) + 
                   I(1 * (spray == "D")) + I(1 * (spray == "E")) + 
                   I(1 * (spray == "F")),
           data = InsectSprays
           ))$coefficients

##### ANCOVA

hist(swiss$Catholic)

swiss = mutate(swiss,CatholicBin = 1 * (Catholic > 50))
swiss %>% head()

g <- ggplot(swiss, aes(x = Agriculture, y = Fertility,  
                  colour =  factor(CatholicBin))) + 
               geom_point(size = 6, colour = 'black') + 
               geom_point(size = 4)

g
fit.swiss <- lm(Fertility ~ Agriculture, data = swiss)

g1 = g + geom_abline(intercept = coef(fit.swiss)[1], slope = coef(fit.swiss)[2], size = 2)
g1

summary(fit.swiss)$coefficients

fit.swiss.b <- lm(Fertility ~ Agriculture * factor(CatholicBin), data= swiss)
summary(fit.swiss.b)$coefficients

g2 = g + geom_abline(intercept = coef(fit.swiss.b)[1], 
                     slope = coef(fit.swiss)[2], size = 2) +
        geom_abline(intercept = coef(fit.swiss.b)[1] + coef(fit.swiss.b)[3], 
                     slope = coef(fit.swiss)[2], size = 2)
g2


g3 = g + geom_abline(intercept = coef(fit.swiss.b)[1], 
                     slope = coef(fit.swiss)[2], size = 2) +
        geom_abline(intercept = coef(fit.swiss.b)[1] + coef(fit.swiss.b)[3], 
                     slope = coef(fit.swiss)[2] + coef(fit.swiss)[4], size = 2)
g3

## ADJUSTMENT 
library(rgl)






###### SLICING

library(caret)
library(kernlab)


inTrain <- createDataPartition(banksPanel$SprEp, p = 0.60, list = FALSE)

training <- banksPanel[inTrain,]
testing <- banksPanel[-inTrain,]
training %>% dim() ; testing %>% dim()

modelFit <- train(SprEp ~ log(`16000001`) + log(`71100001`) + log(`41000007`) +
                            `81100008` + SelMet + `16900008` +
                            log(`31000000`) + `21000003` + Tam + 
                            `71700009` + 
                            log((`71000008` -  `71700009` - `71100001`)) +
                            `81700006` + `49100002` +  
                            log(BMA) + GrCon, 
                  data = training, method = "glm")
modelFit$finalModel

predict <-  predict(modelFit, newdata = testing)


confusionMatrix(predic, testing$SprEp)

print(modelFit$finalModel)
               

 

#### TREE
library(rattle)


formulanow <- paste("EPr", "EAv", "EAp", 
            "DAdm", "Inad", "Comp", "Vol", "Tam", "MkSh", 
            "Rent", "Rc", 
            "TpIns", 
            "RcSrv",
            "SprEa", "Cx", "Rent","IPCA", 
            "SelMet", "MPA4", "MPA2",  "BMR",
            "SelOvr", "BMA", 
            "GrCon", "VelMo",
            sep = " + ")

form <- paste("SprEp", formulanow, sep = " ~ ")

modelFitTree <- train(SprEp ~ Tam + Vol + VelMo + GrCon + Rc + Inad,
                  data = banksPanel, method = "rpart")

fancyRpartPlot(modelFitTree$finalModel)
```


```{r dyn.panel, eval=FALSE, results='hide', include=FALSE}

## DYNAMIC PANEL
library(dynpanel)


dyn.form <- formula(SprEp ~ lnOpTot + lnAtv +
                    + DAdm + DesCap + OtDes +
                    + Inad + RcPd + lnMPA4
                    + SelMet + VelMo + ImpRend  + ImpInd
                    + DepAv + DepAp + DepIf + DepPop
                    + lnROp + ROpCr + RSrv + RPart)

dyn.model <-  
        model.pvrgmm %>% 
        select(SprEp, lnOpTot, lnAtv, DAdm , DesCap, OtDes, Inad, RcPd, 
               lnMPA4, SelMet, VelMo, ImpRend, ImpInd, DepAv, DepAp, DepIf,
               DepPop, lnROp, ROpCr, RSrv, RPart, BANCO) 

dyn.effects <- dpd(formula = dyn.form, data = dyn.model,
                   index = c("DATA", "BANCO"), 1, 20)

```

```{r sur.model, eval=FALSE, results='hide', include=FALSE}
library(units)
library(systemfit)
library(spsur)

sur.model <- spsurml(formula = SprEp ~ Inad + DAdm + DesOp
                     + lnOpTot
                     + ROpCr + RSrv + RPart
                     + DepAv + DepAp + DepPop + DepIf
                     + SelOvr + lnMPA4, 
        type = "sim",         
               data = model.pvrgmm,
        listw = c("BANCO"),
               method = "eigenw")

summary(sur.model)

spsur::lmtestspsur(sur.model)
```


```{r random.forest, eval=FALSE, results='hide', include=FALSE}
library(randomForest)

fit.random <- 
        randomForest(SprEp ~ lnOpTot + lnAtv +
                    + DAdm + DesCap + OtDes +
                    + Inad + RcPd + lnMPA4
                    + SelMet + VelMo + ImpRend  + ImpInd
                    + DepAv + DepAp + DepIf + DepPop
                    + lnROp + ROpCr + RSrv + RPart, 
                           data =  banksPanel, importance = TRUE)

fit.random

cforest(SprEp ~ lnOpTot + lnAtv +
                    + DAdm + DesCap + OtDes +
                    + Inad + RcPd + lnMPA4
                    + SelMet + VelMo + ImpRend  + ImpInd
                    + DepAv + DepAp + DepIf + DepPop
                    + lnROp + ROpCr + RSrv + RPart, 
                           data =  banksPanel,
        controls=cforest_control(mtry=2, mincriterion=0))

getTree(fit.random, k = 1, labelVar = TRUE) %>% plot()

a <- rpart(SprEp ~ lnOpTot + lnAtv +
                    + DAdm + DesCap + OtDes +
                    + Inad + RcPd + lnMPA4
                    + SelMet + VelMo + ImpRend  + ImpInd
                    + DepAv + DepAp + DepIf + DepPop
                    + lnROp + ROpCr + RSrv + RPart, 
           data =  banksPanel, method = "class", subset = TRUE)

rpart
rpart.plot(a)
```
